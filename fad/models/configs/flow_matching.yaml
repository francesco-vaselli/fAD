# a config file for flow matching model 
name: "32-3-mlp-1024-0.001-50"
input_dim: 58
hidden_dim: 32 #was 32 in good results
model_type: mlp
num_layers: 3 # was 4 in good results
dropout_rate: 0.0
use_batch_norm: false
lr: 0.001
batch_size: 1024
reflow_steps: 3
reflow_batches: 50
iterations: 50
print_every: 1
device: null

# some notes on the best configs
# bs=32 and 5 steps is what I did in the hackathon
# bs=1024 and 20 steps is what gives good results now, when training in "rectified" mode AND sampling with 1 timestep